# Awesome-3D-Spatial-Intelligence



## Level 1 -- Low-level 3D cues
### ðŸŒ€ Dynamic Video to Depth Estimation

| Year | Venue | Acronym | Paper | Project | GitHub |
|------|-------|---------|-------|---------|-------------|
| 2019 | ICCV | GLNet | [Self-supervised learning with geometric constraints in monocular video: Connecting flow, depth, and camera](https://openaccess.thecvf.com/content_ICCV_2019/papers/Chen_Self-Supervised_Learning_With_Geometric_Constraints_in_Monocular_Video_Connecting_Flow_ICCV_2019_paper.pdf) | | |
| 2020 | ICLR | DeepV2D | [DeepV2D: Video to Depth with Differentiable Structure from Motion](https://arxiv.org/abs/1812.04605) |  | [GitHub](https://github.com/princeton-vl/DeepV2D) |
| 2020 | SIGGRAPH |  | [Consistent Video Depth Estimation](https://arxiv.org/abs/2004.15021) | [Project](https://roxanneluo.github.io/Consistent-Video-Depth-Estimation/) | [GitHub](https://github.com/facebookresearch/consistent_depth) |
| 2021 | TOG |  | [Consistent depth of moving objects in video](https://dl.acm.org/doi/pdf/10.1145/3450626.3459871) | [Project](https://dynamic-video-depth.github.io/) | [GitHub](https://github.com/google/dynamic-video-depth) |
| 2022 | ACMMM | FMNet | [Less is More: Skip Connections in Video Depth Estimation](https://arxiv.org/pdf/2208.00380) |  | [GitHub](https://github.com/RaymondWang987/FMNet) |
| 2023 | WACV | CODD | [Temporally consistent online depth estimation in dynamic scenes](https://arxiv.org/pdf/2111.09337) | [Project](https://mli0603.github.io/codd/) | [GitHub](https://github.com/facebookresearch/CODD) |
| 2023 | ICCV | MAMo | [Mamo: Leveraging memory and attention for monocular video depth estimation](https://arxiv.org/pdf/2307.14336) | | |
| 2023 | ICCV | NVDS | [Neural Video Depth Stabilizer](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Neural_Video_Depth_Stabilizer_ICCV_2023_paper.pdf) | [Project](https://raymondwang987.github.io/NVDS/) | [GitHub](https://github.com/RaymondWang987/NVDS) |
| 2024 | T-PAMI | NVDS+ | [NVDS+: Towards Efficient and Versatile Neural Stabilizer for Video Depth Estimation](https://arxiv.org/pdf/2307.08695) | [Project](https://raymondwang987.github.io/NVDS/) | [GitHub](https://github.com/RaymondWang987/NVDS) |
| 2025 | ICLR  | DepthAnyVideo | [Depth Any Video with Scalable Synthetic Data](https://arxiv.org/abs/2410.10815) | [Project](https://depthanyvideo.github.io/)  | [GitHub](https://github.com/Nightmare-n/DepthAnyVideo) |
| 2025 | CVPR | DepthCrafter | [DepthCrafter: Generating Consistent Long Depth Sequences for Open-world Videos](https://arxiv.org/abs/2409.02095) | [Project](https://depthcrafter.github.io/) | [GitHub](https://github.com/Tencent/DepthCrafter) |
| 2025 | CVPR | ChronoDepth | [Learning Temporally Consistent Video Depth from Video Diffusion Priors](https://arxiv.org/abs/2406.01493) | [Project](https://xdimlab.github.io/ChronoDepth/) | [GitHub](https://github.com/jiahao-shao1/ChronoDepth) |
| 2025 | CVPR | Video Depth Anything | [Video Depth Anything: Consistent Depth Estimation for Super-Long Videos](https://arxiv.org/abs/2501.12375) | [Project](https://videodepthanything.github.io/)  | [GitHub](https://github.com/DepthAnything/Video-Depth-Anything) |


### ðŸ“· Static Video to Depth Estimation

| Year | Venue      | Acronym | Paper                                                                                                                                               | Project | GitHub |
|------|------------|---------|-----------------------------------------------------------------------------------------------------------------------------------------------------|---------|--------|
| 2018 | CVPR       | GeoNet  | [GeoNet: Unsupervised learning of dense depth, optical flow and camera pose](https://openaccess.thecvf.com/content_cvpr_2018/papers/Yin_GeoNet_Unsupervised_Learning_CVPR_2018_paper.pdf) | â€“ | [GitHub](https://github.com/yzcjtr/GeoNet) |
| 2019 | NeurIPS    | SC-SfMLearner | [Unsupervised scale-consistent depth and ego-motion learning from monocular video](https://proceedings.neurips.cc/paper_files/paper/2019/file/6364d3f0f495b6ab9dcf8d3b5c6e0b01-Paper.pdf) | â€“ | [GitHub](https://github.com/JiawangBian/SC-SfMLearner-Release) |
| 2019 | ICCV       | â€“       | [Depth from videos in the wild: Unsupervised monocular depth learning from unknown cameras](https://openaccess.thecvf.com/content_ICCV_2019/papers/Gordon_Depth_From_Videos_in_the_Wild_Unsupervised_Monocular_Depth_Learning_ICCV_2019_paper.pdf) | â€“ | [GitHub](https://github.com/bolianchen/pytorch_depth_from_videos_in_the_wild) |
| 2019 | ICCV       | â€“       | [Exploiting temporal consistency for real-time video depth estimation](https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_Exploiting_Temporal_Consistency_for_Real-Time_Video_Depth_Estimation_ICCV_2019_paper.pdf) | â€“ | [GitHub](https://github.com/hkzhang-git/ST-CLSTM) |
| 2019 | IEEE Tâ€‘ITS | FlowGRU | [Temporally consistent depth prediction with flowâ€‘guided memory units](https://openaccess.thecvf.com/content/WACV2023/papers/Li_Temporally_Consistent_Online_Depth_Estimation_in_Dynamic_Scenes_WACV_2023_paper.pdf) | [Project](https://cvlab.yonsei.ac.kr/projects/FlowGRU/) | [GitHub](https://github.com/cvlab-yonsei/FlowGRU) |
| 2020 | IEEE RAâ€‘L  | â€“       | [Donâ€™t forget the past: Recurrent depth estimation from monocular video](https://arxiv.org/pdf/2001.02613) | [Project](https://www.trace.ethz.ch/publications/2020/rec_depth_estimation/index.html) | â€“ |
| 2020 | IROS       | FDNet   | [Video depth estimation by fusing flowâ€‘toâ€‘depth proposals](https://ieeexplore.ieee.org/document/9341191) | [Project](https://jiaxinxie97.github.io/Jiaxin-Xie/FDNet/FDNet) | [GitHub](https://github.com/jiaxinxie97/Video-depth-estimation) |
| 2020 | SIGGRAPH   | â€“       | [Consistent video depth estimation](https://arxiv.org/abs/2004.15021) | [Project](https://roxanneluo.github.io/Consistent-Video-Depth-Estimation/) | [GitHub](https://github.com/facebookresearch/consistent_depth) |
| 2021 | CVPR       | CVD     | [Robust consistent video depth estimation](https://arxiv.org/pdf/2012.05901) | [Project](https://robust-cvd.github.io/) | [GitHub](https://github.com/facebookresearch/robust_cvd) |
| 2021 | CVPR       | ESTDepth | [Multiâ€‘view depth estimation using epipolar spatioâ€‘temporal networks](https://openaccess.thecvf.com/content/CVPR2021/papers/Long_Multi-View_Depth_Estimation_Using_Epipolar_Spatio-Temporal_Networks_CVPR_2021_paper.pdf) | [Project](https://www.xxlong.site/ESTDepth/) | [GitHub](https://github.com/xxlong0/ESTDepth) |
| 2021 | CVPR       | ManyDepth | [The temporal opportunist: Selfâ€‘supervised multiâ€‘frame monocular depth](https://arxiv.org/abs/2104.14540) | â€“ | [GitHub](https://github.com/nianticlabs/manydepth) |
| 2021 | ECCV       | SimpleRecon | [Simplerecon: 3D reconstruction without 3D convolutions](https://arxiv.org/abs/2208.14743) | [Project](https://nianticlabs.github.io/simplerecon/) | [GitHub](https://github.com/nianticlabs/simplerecon) |
| 2022 | CVPR       | DepthFormer | [Multiâ€‘frame selfâ€‘supervised depth with transformers](https://openaccess.thecvf.com/content/CVPR2022/papers/Guizilini_Multi-Frame_Self-Supervised_Depth_With_Transformers_CVPR_2022_paper.pdf) | [Project](https://sites.google.com/tri.global/depthformer) | â€“ |
| 2022 | 3DV        | MonoViT | [Monovit: Selfâ€‘supervised monocular depth estimation with a vision transformer](https://arxiv.org/abs/2208.03543) | â€“ | [GitHub](https://github.com/zxcqlf/MonoViT) |
| 2022 | ACM MM     | FMNet   | [Less is more: Consistent video depth estimation with masked frames modeling](https://dl.acm.org/doi/10.1145/3503161.3547713) | â€“ | [GitHub](https://github.com/RaymondWang987/FMNet) |
| 2023 | ICCV       | MAMo    | [MAMo: Leveraging memory and attention for monocular video depth estimation](https://openaccess.thecvf.com/content/ICCV2023/papers/Yasarla_MAMo_Leveraging_Memory_and_Attention_for_Monocular_Video_Depth_Estimation_ICCV_2023_paper.pdf) | â€“ | â€“ |
| 2024 | T-PAMI     | NVDS+   | [NVDS: Towards Efficient and Versatile Neural Stabilizer for Video Depth Estimation](https://arxiv.org/pdf/2307.08695) | [Project](https://raymondwang987.github.io/NVDS/) | [GitHub](https://github.com/RaymondWang987/NVDS) |
| 2024 | ECCV       | FutureDepth | [FutureDepth: Learning to predict the future improves video depth estimation](https://arxiv.org/pdf/2403.12953) | â€“ | â€“ |
| 2025 | CVPR       | ChronoDepth | [Learning Temporally Consistent Video Depth from Video Diffusion Priors](https://arxiv.org/abs/2406.01493) | [Project](https://xdimlab.github.io/ChronoDepth/) | [GitHub](https://github.com/jiahao-shao1/ChronoDepth) |
| 2024 | arXiv      | DepthAnyVideo | [Depth Any Video with Scalable Synthetic Data](https://arxiv.org/abs/2410.10815) | [Project](https://depthanyvideo.github.io/) | [GitHub](https://github.com/Nightmare-n/DepthAnyVideo) |
| 2025 | CVPR       | â€“       | [Video Depth Anything: Consistent Depth Estimation for Superâ€‘Long Videos](https://arxiv.org/abs/2501.12375) | [Project](https://videodepthanything.github.io/) | [GitHub](https://github.com/DepthAnything/Video-Depth-Anything) |


---

### ðŸ“· Camera pose estimation

| Year | Venue | Acronym | Paper | Project | GitHub |
|------|-------|---------|-------|---------|-------------|
| 2014 | ECCV | LSD-SLAM | [LSD-SLAM: Large-scale direct monocular SLAM](https://jakobengel.github.io/pdf/engel14eccv.pdf) | [Project](https://cvg.cit.tum.de/research/vslam/lsdslam?redirect=1) | [GitHub](https://github.com/tum-vision/lsd_slam) |
| 2015 | TRO | ORB-SLAM | [ORB-SLAM: A Versatile and Accurate Monocular SLAM System](https://arxiv.org/abs/1502.00956) | [Project](https://webdiis.unizar.es/~raulmur/orbslam/) | [GitHub](https://github.com/raulmur/ORB_SLAM) |
| 2017 | T-PAMI | DSO | [Direct Sparse Odometry](https://arxiv.org/abs/1607.02565) | [Project](https://cvg.cit.tum.de/research/vslam/dso?redirect=1) | [GitHub](https://github.com/JakobEngel/dso) |
| 2017 | TRO | ORB-SLAM2 | [ORB-SLAM2: An open-source SLAM system for monocular, stereo, and RGB-D cameras](https://arxiv.org/abs/1610.06475) | | [GitHub](https://github.com/raulmur/ORB_SLAM2) |
| 2017 | ICRA | DeepVO | [DeepVO: Towards End-to-End Visual Odometry with Deep Recurrent Convolutional Neural Networks](https://arxiv.org/abs/1709.08429) | [Project](https://senwang.gitlab.io/DeepVO/) | |
| 2020 | CVPR | D3VO | [D3VO: Deep Depth, Deep Pose and Deep Uncertainty for Monocular Visual Odometry](https://arxiv.org/abs/2003.01060) | | [GitHub](https://github.com/as821/D3VO) |
| 2021 | CoRL | TartanVO | [TartanVO: A Generalizable Learning-based VO](https://arxiv.org/abs/2011.00359) | | [GitHub](https://github.com/castacks/tartanvo) |
| 2021 | TITS | DDSO | [Deep Direct Visual Odometry](https://arxiv.org/abs/1912.05101) | | |
| 2021 | T-RO | LF-SLAM | [Line Flow Based Simultaneous Localization and Mapping](https://ieeexplore.ieee.org/abstract/document/9393474) | | |
| 2022 | ICRA | EDPLVO | [EDPLVO: Efficient Direct Point-Line Visual Odometry](https://www.cs.cmu.edu/~kaess/pub/Zhou22icra.pdf) | | |
| 2023 | ICCV | XVO | [XVO: Generalized Visual Odometry via Cross-Modal Self-Training](https://arxiv.org/abs/2309.16772) | [Project](https://genxvo.github.io/) | [GitHub](https://github.com/h2xlab/XVO) |
| 2023 | ICRA | DytanVO | [DytanVO: Joint Refinement of Visual Odometry and Motion Segmentation in Dynamic Environments](https://arxiv.org/abs/2209.08430) | | [GitHub](https://github.com/castacks/DytanVO) |
| 2023 | IROS | StereoVO | [Stereo VO with Point and Line Matching using Attention GNN](https://arxiv.org/abs/2308.01125) | | |
| 2023 | ICRA | Structure PLP-SLAM | [Structure PLP-SLAM: Efficient Sparse Mapping using Point, Line and Plane](https://arxiv.org/abs/2207.06058) | | [GitHub](https://github.com/PeterFWS/Structure-PLP-SLAM) |
| 2024 | ECCV | DPV-SLAM | [Deep Patch Visual SLAM](https://arxiv.org/abs/2408.01654) | | [GitHub](https://github.com/princeton-vl/DPVO) |
| 2024 | ECCV | RLVO | [Reinforcement Learning Meets Visual Odometry](https://arxiv.org/abs/2407.15626) | | [GitHub](https://github.com/uzh-rpg/rl_vo) |
| 2024 | RA-L | | [Efficient Camera Exposure Control for VO via Deep RL](https://arxiv.org/abs/2408.17005) | | [GitHub](https://github.com/ShuyangUni/drl_exposure_ctrl) |
| 2024 | T-ASE | UL-SLAM | [UL-SLAM: A Universal Monocular Line-Based SLAM via Unifying Structural and Non-Structural Constraints](https://ieeexplore.ieee.org/document/10488029) | | [GitHub](https://github.com/jhch1995/UL-SLAM-Mono) |
| 2023 | NeurIPS | DPVO | [Deep Patch Visual Odometry](https://arxiv.org/abs/2208.04726) | | [GitHub](https://github.com/princeton-vl/DPVO) |
| 2025 | CVPR | AnyCam | [AnyCam: Learning to Recover Camera Poses and Intrinsics from Casual Videos](https://arxiv.org/abs/2503.23282) | [Project](https://fwmb.github.io/anycam/) | [GitHub](https://github.com/Brummi/anycam) |
| 2025 | CVPR | DynPose | [Dynamic Camera Poses and Where to Find Them](https://arxiv.org/abs/2504.17788) | [Project](https://research.nvidia.com/labs/dir/dynpose-100k/) | |
| 2025 | T-RO | AirSLAM | [AirSLAM: An Efficient and Illumination-Robust Point-Line SLAM System](https://arxiv.org/abs/2408.03520) | [Project](https://xukuanhit.github.io/airslam/) | [GitHub](https://github.com/sair-lab/AirSLAM) |

---

### ðŸ“· 3D tracking

| Year | Venue | Acronym | Paper | Project | GitHub |
|------|-------|---------|-------|---------|-------------|
| 2023 | ICCV | OmniMotion | [Tracking Everything Everywhere All at Once](https://arxiv.org/abs/2306.05422) | [Project](https://omnimotion.github.io/) | [GitHub](https://github.com/qianqianwang68/omnimotion) |
| 2024 | ECCV | OmniTrackFast | [Track Everything Everywhere Fast and Robustly](https://arxiv.org/abs/2403.17931) | [Project](https://timsong412.github.io/FastOmniTrack/) | [GitHub](https://github.com/TimSong412/OmniTrackFast) |
| 2024 | CVPR | SpatialTracker | [SpatialTracker: Tracking Any 2D Pixels in 3D Space](https://arxiv.org/abs/2404.04319) | [Project](https://henry123-boy.github.io/SpaTracker/) | [GitHub](https://github.com/henry123-boy/SpaTracker) |
| 2025 |  T-PAMI | SceneTracker | [SceneTracker: Long-term Scene Flow Estimation Network](https://arxiv.org/abs/2403.19924) | | [GitHub](https://github.com/wwsource/SceneTracker) |
| 2025 | ICLR | DELTA | [DELTA: Dense Efficient Long-range 3D Tracking for any video](https://arxiv.org/abs/2410.24211) | [Project](https://snap-research.github.io/DELTA/) | [GitHub](https://github.com/snap-research/) |
| 2025 | CVPR | Seurat | [Seurat: From Moving Points to Depth](https://arxiv.org/abs/2504.14687) | [Project](https://seurat-cvpr.github.io/) | [GitHub](https://github.com/cvlab-kaist/seurat) |
| 2025 | arXiv | TAPIP3D | [TAPIP3D: Tracking Any Point in Persistent 3D Geometry](https://arxiv.org/abs/2504.14717) | [Project](https://tapip3d.github.io/) | [GitHub](https://github.com/zbw001/TAPIP3D) |


---

### ðŸŽ¥ Unifying depth and camera pose estimation

| Year | Venue | Acronym | Paper | Project | GitHub |
|------|-------|---------|-------|---------|-------------|
| 2021 | CVPR  | Robust-CVD | [Robust consistent video depth estimation](https://arxiv.org/abs/2012.05901) | [Project](https://robust-cvd.github.io/) | [GitHub](https://github.com/facebookresearch/robust_cvd) |
| 2022 | ECCV  | CasualSAM | [Structure and motion from casual videos](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136930020.pdf) |         |             |
| 2025 | CVPR    | MegaSam | [Megasam: Accurate, fast, and robust structure and motion from casual dynamic videos](https://arxiv.org/abs/2412.04463) | [Project](https://mega-sam.github.io/) | [GitHub](https://github.com/mega-sam/mega-sam) |
| 2025 | 3DV    |  Spann3R | [3D reconstruction with spatial memory](https://arxiv.org/abs/2408.16061) | [Project](https://hengyiwang.github.io/projects/spanner) | [GitHub](https://github.com/HengyiWang/spann3r) |
| 2025 | ICLR    | MonST3R | [MonST3R: A Simple Approach for Estimating Geometry in the Presence of Motion](https://arxiv.org/abs/2410.03825) | [Project](https://monst3r-project.github.io/) | [GitHub](https://github.com/Junyi42/monst3r) |
| 2025 | CVPR    | Align3R | [Align3R: Aligned Monocular Depth Estimation for Dynamic Videos](https://arxiv.org/abs/2412.03079) | [Project](https://igl-hkust.github.io/Align3R.github.io/) | [GitHub](https://github.com/jiah-cloud/Align3R) |
| 2025 | CVPR    | CUT3R | [Continuous 3D Perception Model with Persistent State](https://arxiv.org/abs/2501.12387) | [Project](https://cut3r.github.io/) | [GitHub](https://github.com/CUT3R/CUT3R) |
| 2025 | ICCV    | Easi3R  | [Easi3R: Estimating Disentangled Motion from DUSt3R Without Training](https://arxiv.org/abs/2503.24391) | [Project](https://easi3r.github.io/) | [GitHub](https://github.com/Inception3D/Easi3R) |
| 2025 | ICCV    | Geometrycrafter | [Geometrycrafter: Consistent geometry estimation for open-world videos with diffusion priors](https://arxiv.org/abs/2504.01016) | [Project](https://geometrycrafter.github.io/) | [GitHub](https://github.com/TencentARC/GeometryCrafter) |
| 2025 | ICCV     | Aether  | [Aether: Geometric-aware unified world modeling](https://arxiv.org/abs/2503.18945) | [Project](https://aether-world.github.io/) | [GitHub](https://github.com/OpenRobotLab/Aether) |
| 2025 | ICCV    | Geo4D   | [Geo4d: Leveraging video generators for geometric 4D scene reconstruction](https://arxiv.org/abs/2504.07961) | [Project](https://geo4d.github.io/) | [GitHub](https://github.com/jzr99/Geo4D) |
| 2025 | arXiv    | UniGeo  | [UniGeo: Taming Video Diffusion for Unified Consistent Geometry Estimation](https://arxiv.org/abs/2505.24521) | [Project](https://sunyangtian.github.io/UniGeo-web/) | [GitHub](https://github.com/SunYangtian/UniGeo) |
| 2025 | arXiv    | Point3R  | [Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory](https://arxiv.org/abs/2507.02863) | [Project](https://ykiwu.github.io/Point3R/) | [GitHub](https://github.com/YkiWu/Point3R) |
| 2025 | arXiv    | StreamVGGT  | [Streaming 4D Visual Geometry Transformer](https://arxiv.org/abs/2507.11539) | [Project](https://wzzheng.net/StreamVGGT/) | [GitHub](https://github.com/wzzheng/StreamVGGT) |
| 2025 | arXiv    | PI^3  | [Ï€^3: Scalable Permutation-Equivariant Visual Geometry Learning](https://arxiv.org/abs/2507.13347) | [Project](https://yyfz.github.io/pi3/) | [GitHub](https://github.com/yyfz/Pi3) |

### ðŸŽ¥ Unifying depth, camera pose, and 3D tracking

| Year | Venue | Acronym | Paper | Project | GitHub |
|------|-------|---------|-------|---------|-------------|
| 2024 | NeurIPS   | TracksTo4D | [Fast Encoder-Based 3D from Casual Videos via Point Track Processing](https://arxiv.org/abs/2404.07097)     | [Project](https://tracks-to-4d.github.io/) | [GitHub](https://github.com/NVlabs/tracks-to-4d) |
| 2025 | CVPR      | Uni4D       | [Uni4D: Unifying Visual Foundation Models for 4D Modeling from a Single Video](https://arxiv.org/abs/2503.21761)  | [Project](https://davidyao99.github.io/uni4d/) | [GitHub](https://github.com/Davidyao99/uni4d/tree/main) |
| 2025 | arXiv     | BA-Track | [Back on Track: Bundle Adjustment for Dynamic Scene Reconstruction](https://arxiv.org/abs/2504.14516)           | [Project](https://wrchen530.github.io/projects/batrack/) | |  
| 2025 | arXiv     | TrackingWorld | [TrackingWorld: World-centric Monocular 3D Tracking of Almost All Pixels](https://github.com/IGL-HKUST/TrackingWorld)           | [Project](https://github.com/IGL-HKUST/TrackingWorld) | [GitHub](https://github.com/IGL-HKUST/TrackingWorld) | 
| 2025 | CVPR     | Stereo4D    | [Stereo4D: Learning How Things Move in 3D from Internet Stereo Videos](https://arxiv.org/abs/2412.09621)       | [Project](https://stereo4d.github.io/) | [GitHub](https://github.com/Stereo4d/stereo4d-code) | 
| 2025 | arXiv     | DPM | [Dynamic Point Maps: A Versatile Representation for Dynamic 3D Reconstruction](https://arxiv.org/abs/2503.16318) | [Project](https://www.robots.ox.ac.uk/~vgg/research/dynamic-point-maps/) | |
| 2025 | ICCV     | St4RTrack   | [St4RTrack: Simultaneous 4D Reconstruction and Tracking in the World](https://arxiv.org/abs/2504.13152)         | [Project](https://st4rtrack.github.io/) | |
| 2025 | arXiv     | POMATO      | [POMATO: Marrying Pointmap Matching with Temporal Motion for Dynamic 3D Reconstruction](https://arxiv.org/abs/2504.05692) | | [GitHub](https://github.com/wyddmw/POMATO) |
| 2025 | arXiv     | D^2USt3R    | [D^2USt3R: Enhancing 3D Reconstruction with 4D Pointmaps for Dynamic Scenes](https://arxiv.org/abs/2504.06264)    | [Project](https://cvlab-kaist.github.io/DDUSt3R/) | |
| 2025 | CVPR      | VGGT        | [VGGT: Visual Geometry Grounded Transformer](https://arxiv.org/abs/2503.11651)  | [Project](https://vgg-t.github.io/) | [GitHub](https://github.com/facebookresearch/vggt) |
| 2025 | CVPR      | Zero-MSF | [Zero-Shot Monocular Scene Flow Estimation in the Wild](https://arxiv.org/abs/2501.10357)                        | [Project](https://research.nvidia.com/labs/lpr/zero_msf//) | [GitHub](https://github.com/SunYangtian/UniGeo) |
| 2025 | ICCV | SpatialTrackerV2 | [SpatialTrackerV2: 3D Point Tracking Made Easy](https://arxiv.org/abs/2507.12462) | [Project](https://spatialtracker.github.io/) | [GitHub](https://github.com/henry123-boy/SpaTrackerV2) |

## Level 4 -- Interaction among scene components

### SMPL-based human-centric interaction - HOI

| Year | Venue | Acronym | Paper | Project | GitHub |
|------|-------|---------|-------|---------|-------------|
| 2016 | TOG | PiGraphs | [PiGraphs: learning interaction snapshots from observations](https://dl.acm.org/doi/10.1145/2897824.2925867)     | | |
| 2020 | ECCV | PHOSA | [Perceiving 3D Human-Object Spatial Arrangements from a Single Image in the Wild](https://arxiv.org/abs/2007.15649)     | [Project](https://jasonyzhang.com/phosa/) | [GitHub](https://github.com/facebookresearch/phosa) |
| 2021 | | D3D-HOI | [3d-hoi: Dynamic 3d human-object interactions from videos](https://arxiv.org/abs/2108.08420)     | | [GitHub](https://github.com/facebookresearch/d3d-hoi) |
| 2021 | CVPR | GraviCap | [Gravity-Aware Monocular 3D Human-Object Reconstruction](https://arxiv.org/abs/2108.08844)     | [Project](https://4dqv.mpi-inf.mpg.de/GraviCap/) | [GitHub](https://github.com/rishabhdabral/gravicap) |
| 2022 | CVPR | BEHAVE | [BEHAVE: Dataset and Method for Tracking Human Object Interactions](https://arxiv.org/abs/2204.06950)     | [Project](https://virtualhumans.mpi-inf.mpg.de/behave/) | [GitHub](https://github.com/xiexh20/behave-dataset) |
| 2022 | ECCV | CHORE | [CHORE: Contact, Human and Object REconstruction from a single RGB image](https://arxiv.org/abs/2204.02445)     | [Project](https://virtualhumans.mpi-inf.mpg.de/chore/) | [GitHub](https://github.com/xiexh20/CHORE) |
| 2023 | ICCV | CHAIRS | [Full-Body Articulated Human-Object Interaction](https://arxiv.org/abs/2212.10621)     | [Project](https://yzhu.io/publication/hoi2023iccv/) | [GitHub](https://github.com/jnnan/chairs) |
| 2023 | ICCV | Humans in 4D | [Humans in 4D: Reconstructing and Tracking Humans with Transformers](https://arxiv.org/abs/2305.20091)     | [Project](https://shubham-goel.github.io/4dhumans/) | [GitHub](https://github.com/shubham-goel/4D-Humans) |
| 2023 | IJCAI | StackFLOW | [StackFLOW: Monocular Human-Object Reconstruction by Stacked Normalizing Flow with Offset](https://arxiv.org/abs/2407.20545)     | [Project](https://huochf.github.io/StackFLOW/) | [GitHub](https://github.com/huochf/StackFLOW) |
| 2023 | CVPR | VisTracker | [Visibility Aware Human-Object Interaction Tracking from Single RGB Camera](https://arxiv.org/abs/2303.16479)     | [Project](https://virtualhumans.mpi-inf.mpg.de/VisTracker/) | [GitHub](https://github.com/xiexh20/VisTracker) |
| 2024 | IJCV | InterCap | [InterCap: Joint Markerless 3D Tracking of Humans and Objects in Interaction](https://arxiv.org/abs/2209.12354)     | [Project](https://intercap.is.tue.mpg.de/) | [GitHub](https://github.com/YinghaoHuang91/InterCap/tree/master) |
| 2024 | MM | WildHOI | [Monocular Human-Object Reconstruction in the Wild](https://arxiv.org/abs/2407.20566)     | [Project](https://huochf.github.io/WildHOI/) | [GitHub](https://github.com/huochf/WildHOI) |
| 2024 | CVPR | I'M HOI | [I'M HOI: Inertia-aware Monocular Capture of 3D Human-Object Interactions](https://arxiv.org/abs/2312.08869)     | [Project](https://afterjourney00.github.io/IM-HOI.github.io/) | [GitHub](https://github.com/AfterJourney00/IMHD-Dataset) |
| 2024 | CVPR | HDM | [Template Free Reconstruction of Human-object Interaction with Procedural Interaction Generation](https://arxiv.org/abs/2312.07063)     | [Project](https://virtualhumans.mpi-inf.mpg.de/procigen-hdm/) | [GitHub](https://github.com/xiexh20/HDM) |
| 2024 |  | InterTrack | [InterTrack: Tracking Human Object Interaction without Object Templates](https://arxiv.org/abs/2408.13953)     | [Project](https://virtualhumans.mpi-inf.mpg.de/InterTrack/) | |
| 2024 | NeurIPS | InterDreamer | [InterDreamer: Zero-Shot Text to 3D Dynamic Human-Object Interaction](https://arxiv.org/abs/2403.19652)     | [Project](https://sirui-xu.github.io/InterDreamer/) | |


### SMPL-based human-centric interaction - HSI

| Year | Venue | Acronym | Paper | Project | GitHub |
|------|-------|---------|-------|---------|-------------|
| 2019 | ICCV | PROX | [Resolving 3D Human Pose Ambiguities with 3D Scene Constraints](https://arxiv.org/abs/1908.06963)     | [Project](https://prox.is.tue.mpg.de/) | [GitHub](https://github.com/mohamedhassanmus/prox) |
| 2020 | ECCV | HMP | [Long-term Human Motion Prediction with Scene Context](https://arxiv.org/abs/2007.03672)     | [Project](https://zhec.github.io/hmp/) | [GitHub](https://github.com/ZheC/GTA-IM-Dataset) |
| 2022 | CVPR | RICH | [Capturing and Inferring Dense Full-Body Human-Scene Contact](https://arxiv.org/abs/2206.09553)     | [Project](https://rich.is.tue.mpg.de/) | [GitHub](https://github.com/paulchhuang/bstro) |
| 2022 | ECCV | SitComs3D | [The One Where They Reconstructed 3D Humans and Environments in TV Shows](https://arxiv.org/abs/2204.06950)     | [Project](https://ethanweber.me/sitcoms3D/) | [GitHub](https://github.com/ethanweber/sitcoms3D) |
| 2023 | CVPR | CIRCLE | [CIRCLE: Capture In Rich Contextual Environments](https://arxiv.org/abs/2303.17912)     | | [GitHub](https://github.com/Stanford-TML/circle_dataset) |
| 2024 | CVPR | TRUMANS | [Scaling Up Dynamic Human-Scene Interaction Modeling](https://arxiv.org/pdf/2403.08629)     | [Project](https://jnnan.github.io/trumans/) | [GitHub](https://github.com/jnnan/trumans_utils) |
| 2025 | | JOSH | [InterDreamer: Zero-Shot Text to 3D Dynamic Human-Object Interaction](https://arxiv.org/abs/2501.02158)     | [Project](https://genforce.github.io/JOSH/) | [GitHub](https://github.com/genforce/JOSH) |
| 2025 | CVPR | ODHSR | [ODHSR: Online Dense 3D Reconstruction of Humans and Scenes from Monocular Videos](https://arxiv.org/abs/2504.13167)     | [Project](https://eth-ait.github.io/ODHSR/) | |


### SMPL-based human-centric interaction - HHI

| Year | Venue | Acronym | Paper | Project | GitHub |
|------|-------|---------|-------|---------|-------------|
| 2021 | ICCV | ROMP | [Monocular, One-stage, Regression of Multiple 3D People](https://arxiv.org/abs/2008.12272)     | | [GitHub](https://github.com/Arthur151/ROMP) |
| 2022 | CVPR | BEV | [Putting People in their Place: Monocular Regression of 3D People in Depth](https://arxiv.org/abs/2112.08274)     | [Project](https://www.yusun.work/BEV/BEV.html) | [GitHub](https://github.com/Arthur151/ROMP) |
| 2023 | Siggraph Asia | CloseMoCap | [Reconstructing Close Human Interactions from Multiple Views](https://arxiv.org/abs/2401.16173)     | | [GitHub](https://github.com/zju3dv/CloseMoCap) |
| 2023 | CVPR| Hi4D | [Hi4D: 4D Instance Segmentation of Close Human Interaction](https://arxiv.org/abs/2303.15380)     | [Project](https://yifeiyin04.github.io/Hi4D/) | [GitHub](https://github.com/yifeiyin04/Hi4D) |
| 2024 | CVPR | BUDDI | [Generative Proxemics: A Prior for 3D Social Interaction from Images](https://arxiv.org/abs/2306.09337)     | [Project](https://muelea.github.io/buddi/) | [GitHub](https://github.com/muelea/buddi) |
| 2024 | CVPR | CloseInt | [Closely Interactive Human Reconstruction with Proxemics and Physics-Guided Adaption](https://arxiv.org/abs/2404.11291)     | | [GitHub](https://github.com/boycehbz/HumanInteraction) |
| 2024 | CVPR | MultiPhys | [MultiPhys: Multi-Person Physics-aware 3D Motion Estimation](https://arxiv.org/abs/2404.11987)     | [Project](https://www.iri.upc.edu/people/nugrinovic/multiphys/) | [GitHub](https://github.com/nicolasugrinovic/multiphys) |
| 2024 | ECCV | AvatarPose | [AvatarPose: Avatar-guided 3D Pose Estimation of Close Human Interaction from Sparse Multi-view Videos](https://arxiv.org/abs/2408.02110)     | [Project](https://eth-ait.github.io/AvatarPose/) | [GitHub](https://github.com/eth-ait/AvatarPose) |
| 2024 | NeurIPS | Harmony4D | [Harmony4D: A Video Dataset for In-The-Wild Close Human Interactions](https://arxiv.org/abs/2410.20294)     | [Project](https://jyuntins.github.io/harmony4d/) | [GitHub](https://github.com/jyuntins/harmony4d) |


### Appearance-rich human-centric interaction

| Year | Venue | Acronym | Paper | Project | GitHub |
|------|-------|---------|-------|---------|-------------|
| 2022 | ECCV | NeuMan | [NeuMan: Neural Human Radiance Field from a Single Video](https://arxiv.org/abs/2203.12575)     | [Project](https://machinelearning.apple.com/research/neural-human-radiance-field) | [GitHub](https://github.com/apple/ml-neuman) |
| 2023 | ICCV | HOSNeRF | [HOSNeRF: Dynamic Human-Object-Scene Neural Radiance Fields from a Single Video](https://arxiv.org/abs/2304.12281)     | [Project](https://showlab.github.io/HOSNeRF/) | [GitHub](https://github.com/TencentARC/HOSNeRF) |


### Egocentric human-centric interaction

| Year | Venue | Acronym | Paper | Project | GitHub |
|------|-------|---------|-------|---------|-------------|
| 2021 | ICCV | H2O | [H2O: Two Hands Manipulating Objects for First Person Interaction Recognition](https://arxiv.org/abs/2104.11181)     |  | |
| 2022 | CVPR | HOI4D | [HOI4D: A 4D Egocentric Dataset for Category-Level Human-Object Interaction](https://arxiv.org/abs/2203.01577)     |  | |
| 2023 |  | Aria | [Project Aria: A New Tool for Egocentric Multi-Modal AI Research](https://arxiv.org/abs/2308.13561)     |  | |
| 2023 | MICCAI  | POV-Surgery | [POV-Surgery: A Dataset for Egocentric Hand and Tool Pose Estimation During Surgical Activities](https://arxiv.org/abs/2307.10387)     | [Project](https://batfacewayne.github.io/POV_Surgery_io/)  | [GitHub](https://github.com/BatFaceWayne/POV_Surgery) |
| 2024 | CVPR  | Ego-Exo4D | [Ego-Exo4D: Understanding Skilled Human Activity from First- and Third-Person Perspectives](https://arxiv.org/abs/2311.18259)     | [Project](https://ego-exo4d-data.org/)  | |
| 2024 |   | Nymeria | [Nymeria: A Massive Collection of Multimodal Egocentric Daily Motion in the Wild](https://arxiv.org/abs/2406.09905)     | [Project](https://www.projectaria.com/datasets/nymeria/)  | |
| 2025 | CVPR | HOT3D | [Introducing HOT3D: An Egocentric Dataset for 3D Hand and Object Tracking](https://arxiv.org/abs/2406.09598)     | [Project](https://facebookresearch.github.io/hot3d/)  | |



## Level 5 -- Incorporation of physical laws and constraints


### Dynamic 4D human simulation with physics

| Year | Venue | Acronym | Paper | Project | GitHub |
|------|-------|---------|-------|---------|-------------|
| 1995 | Siggraph  | | [Animating human athletics](https://arxiv.org/abs/2302.06108)     | | |
| 2002 | TOG   | | [Interactive control of avatars animated with human motion data](https://graphics.cs.cmu.edu/projects/Avatar/avatar.pdf)     | | |
| 2007 | TOG  | SIMBICON | [Simbicon: Simple biped locomotion control](https://dl.acm.org/doi/10.1145/1276377.1276509)     | | |
| 2007 | Siggraph  | | [Construction and optimal search of interpolated motion graphs](https://dl.acm.org/doi/abs/10.1145/1276377.1276510)     | | |
| 2007 | Siggraph  | | [Near-optimal Character Animation with Continuous Control](https://dl.acm.org/doi/10.1145/1276377.1276386)     | | |
| 2010 | Siggraph Asia   | | [Motion fields for interactive character locomotion](https://dl.acm.org/doi/10.1145/1882261.1866160)     | | |
| 2010 | TOG  | | [Generalized biped walking control](https://dl.acm.org/doi/10.1145/1778765.1781156)     | | |
| 2010 | TOG  | | [Spatial relationship preserving character motion adaptation](https://dl.acm.org/doi/10.1145/1778765.1778770)     | | |
| 2012 | TOG   | | [Continuous character control with low-dimensional embeddings](https://dl.acm.org/doi/abs/10.1145/2185520.2185524)     | | |
| 2014 | TOG   | | [Learning bicycle stunts](https://dl.acm.org/doi/10.1145/2601097.2601121)     | | |
| 2016 | NeurIPS   | GAIL | [Generative Adversarial Imitation Learning](https://arxiv.org/abs/1606.03476)     | | |
| 2017 | TOG   | PFNN | [Phase-functioned neural networks for character control](https://dl.acm.org/doi/10.1145/3072959.3073663)     | | [GitHub](http://github.com/sreyafrancis/PFNN) |
| 2017 | TOG   | | [Learning to schedule control fragments for physics-based characters using deep q-learning](https://dl.acm.org/doi/10.1145/3083723)     | | |
| 2018 | TOG   | MANN | [Mode-adaptive neural networks for quadruped motion control](https://dl.acm.org/doi/10.1145/3197517.3201366)     | | [GitHub](https://github.com/cghezhang/MANN) |
| 2018 | TOG   | | [Learning basketball dribbling skills using trajectory optimization and deep reinforcement learning](https://dl.acm.org/doi/10.1145/3197517.3201315)     | | |
| 2018 | TOG   | DeepMimic | [DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills](https://arxiv.org/abs/1804.02717)     | | [GitHub](https://github.com/xbpeng/DeepMimic) |
| 2020 | | UniCon | [UniCon: Universal Neural Controller For Physics-based Character Motion](https://arxiv.org/abs/2011.15119)     | [Project](https://research.nvidia.com/labs/toronto-ai/unicon/) | |
| 2020 | TOG | ScaDiver | [A scalable approach to control diverse behaviors for physically simulated characters](https://dl.acm.org/doi/10.1145/3386569.3392381)     | [Project](https://research.facebook.com/publications/a-scalable-approach-to-control-diverse-behaviors-for-physically-simulated-characters/) | [GitHub](https://github.com/facebookresearch/ScaDiver) |
| 2020 | Siggraph   | MotionVAEs | [Character Controllers using Motion VAEs](https://arxiv.org/abs/2103.14274)     | | [GitHub](https://github.com/electronicarts/character-motion-vaes) |
| 2021 | TOG | AMP | [AMP: Adversarial Motion Priors for Stylized Physics-Based Character Control](https://arxiv.org/abs/2104.02180)     |  |  |
| 2022 | NeurIPS | MoCapAct | [MoCapAct: A Multi-Task Dataset for Simulated Humanoid Control](https://arxiv.org/abs/2208.07363)     | [Project](https://microsoft.github.io/MoCapAct/) | [GitHub](https://github.com/microsoft/MoCapAct) |
| 2022 | Siggraph Asia | PADL | [PADL: Language-Directed Physics-Based Character Control](https://arxiv.org/abs/2301.13868)     | | [GitHub](https://github.com/nv-tlabs/PADL) |
| 2022 | TOG | ASE | [ASE: Large-Scale Reusable Adversarial Skill Embeddings for Physically Simulated Characters](https://arxiv.org/abs/2205.01906)     | [Project](https://xbpeng.github.io/projects/ASE/index.html) | [GitHub](https://github.com/nv-tlabs/ASE) |
| 2022 | TOG | ControlVAE | [ControlVAE: Model-Based Learning of Generative Controllers for Physics-Based Characters](https://arxiv.org/abs/2210.06063)     | [Project](https://heyuanyao-pku.github.io/Control-VAE/) | [GitHub](https://github.com/heyuanYao-pku/Control-VAE) |
| 2023 | Siggraph | CALM | [CALM: Conditional Adversarial Latent Models for Directable Virtual Characters](https://arxiv.org/abs/2305.02195)     | [Project](https://research.nvidia.com/labs/par/calm/) | [GitHub](https://github.com/NVlabs/CALM) |
| 2023 | Siggraph | | [Simulation and Retargeting of Complex Multi-Character Interactions](https://arxiv.org/abs/2305.20041)     | | [GitHub](https://github.com/JackZhouSz/InteractionGraph) |
| 2023 | Siggraph | PMP | [PMP: Learning to Physically Interact with Environments using Part-wise Motion Priors](https://arxiv.org/abs/2305.03249)     | | [GitHub](https://github.com/jinseokbae/pmp) |
| 2023 | CVPR   | | [Trace and Pace: Controllable Pedestrian Animation via Guided Trajectory Diffusion](https://arxiv.org/abs/2304.01893)     | [Project](https://research.nvidia.com/labs/toronto-ai/trace-pace/) | [GitHub](https://github.com/nv-tlabs/trace) |
| 2023 | TOG   | | [Learning Physically Simulated Tennis Skills from Broadcast Videos](https://dl.acm.org/doi/10.1145/3592408)     | [Project](https://research.nvidia.com/labs/toronto-ai/vid2player3d/) | [GitHub](https://github.com/nv-tlabs/vid2player3d) |
| 2024 | 3DV   | | [Physically Plausible Full-Body Hand-Object Interaction Synthesis](https://arxiv.org/abs/2309.07907)     | [Project](https://eth-ait.github.io/phys-fullbody-grasp/) | |
| 2024 | NeurIPS   | Omnigrasp | [Omnigrasp: Grasping Diverse Objects with Simulated Humanoids](https://arxiv.org/abs/2407.11385)     | | [GitHub](https://github.com/ZhengyiLuo/Omnigrasp) |
| 2024 | Siggraph   | SuperPADL | [SuperPADL: Scaling Language-Directed Physics-Based Control with Progressive Supervised Distillation](https://arxiv.org/abs/2407.10481)     | [Project](https://xbpeng.github.io/projects/SuperPADL/) | |
| 2024 | Siggraph Asia  | PDP | [PDP: Physics-Based Character Animation via Diffusion Policy](https://arxiv.org/abs/2406.00960)     |  | |
| 2024 | TOG   | MaskedMimic | [MaskedMimic: Unified Physics-Based Character Control Through Masked Motion Inpainting](https://arxiv.org/abs/2409.14393)     | [Project](https://research.nvidia.com/labs/par/maskedmimic/) | [GitHub](https://github.com/NVlabs/ProtoMotions) |
| 2024 | CVPR   | PACER++ | [PACER+: On-Demand Pedestrian Animation Controller in Driving Scenarios](https://arxiv.org/abs/2404.19722)     | | [GitHub](https://github.com/IDC-Flash/PacerPlus) |
| 2025 | ICLR   | CLoSD | [CLoSD: Closing the Loop between Simulation and Diffusion for multi-task character control](https://arxiv.org/abs/2410.03441)     | [Project](https://guytevet.github.io/CLoSD-page/) | [GitHub](https://github.com/GuyTevet/CLoSD) |
| 2025 | ICLR   | | [Hierarchical World Models as Visual Whole-Body Humanoid Controllers](https://arxiv.org/abs/2405.18418)     | [Project](https://www.nicklashansen.com/rlpuppeteer/) | [GitHub](https://github.com/nicklashansen/puppeteer) |
| 2025 | CVPR   | SkillMimic | [SkillMimic: Learning Basketball Interaction Skills from Demonstrations](https://arxiv.org/abs/2408.15270)     | [Project](https://ingrid789.github.io/SkillMimic/) | [GitHub](https://github.com/wyhuai/SkillMimic) |
| 2025 | ICRA   | HOVER | [HOVER: Versatile Neural Whole-Body Controller for Humanoid Robots](https://arxiv.org/abs/2410.21229)     | [Project](https://hover-versatile-humanoid.github.io/) | [GitHub](https://github.com/NVlabs/HOVER/) |
| 2025 | RSS   | ASAP | [ASAP: Aligning Simulation and Real-World Physics for Learning Agile Humanoid Whole-Body Skills](https://arxiv.org/abs/2502.01143)     | [Project](https://agile.human2humanoid.com/) | [GitHub](https://github.com/LeCAR-Lab/ASAP) |
| 2025 |   | UniPhys | [UniPhys: Unified Planner and Controller with Diffusion for Flexible Physics-Based Character Control](https://arxiv.org/abs/2504.12540)     | [Project](https://wuyan01.github.io/uniphys-project/) | |

### 3D scene reconstruction with physical plausibility
| Year | Venue | Acronym | Paper | Project | GitHub |
|------|-------|---------|-------|---------|-------------|
| 2022 | CVPR   | AugNeRF | [Aug-NeRF: Training Stronger Neural Radiance Fields with Triple-Level Physically-Grounded Augmentations](https://arxiv.org/abs/2207.01164)     | | [GitHub](https://github.com/VITA-Group/Aug-NeRF) |
| 2024 | ECCV   | PhysDreamer | [PhysDreamer: Physics-Based Interaction with 3D Objects via Video Generation](https://arxiv.org/abs/2404.13026)     | [Project](https://physdreamer.github.io/) | [GitHub](https://github.com/a1600012888/PhysDreamer) |
| 2024 | Siggraph Asia   | | [Planar Reflection-Aware Neural Radiance Fields](https://arxiv.org/abs/2411.04984)     | | |
| 2024 | NeurIPS   | PhyRecon | [Phyrecon: Physically plausible neural scene reconstruction](https://arxiv.org/abs/2404.16666)     | [Project](https://phyrecon.github.io/) | [GitHub](https://github.com/PhyRecon/PhyRecon) |
| 2025 | ICML   | PhysicsNeRF | [PhysicsNeRF: Physics-Guided 3D Reconstruction from Sparse Views](https://arxiv.org/abs/2505.23481)     | | [GitHub](https://github.com/bmrayan/PhysicsNeRF) |
| 2025 | CVPR   | PBR-NeRF | [PBR-NeRF: Inverse Rendering with Physics-Based Neural Fields](https://arxiv.org/abs/2505.23481)     | | [GitHub](https://github.com/s3anwu/pbrnerf) |
| 2025 |   | CAST | [CAST: Component-Aligned 3D Scene Reconstruction from an RGB Image](https://arxiv.org/abs/2502.12894)     | [Project](https://sites.google.com/view/cast4) | |
